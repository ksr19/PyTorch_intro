{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9cCcfxoMm2cg"
      },
      "source": [
        "Будем практиковаться на датасете:\n",
        "https://www.kaggle.com/c/avito-demand-prediction\n",
        "\n",
        "Ваша задача:\n",
        "1. Создать Dataset для загрузки данных (используем только числовые данные)\n",
        "2. Обернуть его в Dataloader\n",
        "3. Написать архитектуру сети, которая предсказывает число показов на основании числовых данных (вы всегда можете нагенерить дополнительных факторов). Сеть должна включать BatchNorm слои и Dropout (или НЕ включать, но нужно обосновать)\n",
        "4. Учить будем на функцию потерь с кагла (log RMSE) - нужно её реализовать\n",
        "5. Сравните сходимость Adam, RMSProp и SGD, сделайте вывод по качеству работы модели\n",
        "\n",
        "train-test разделение нужно сделать с помощью sklearn random_state=13, test_size = 0.25\n",
        "\n",
        "Вопросы? в личку @Kinetikm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9NVe3edKmOK0",
        "outputId": "45d92c1f-0712-4bd7-a9cc-3a832350f5c2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 74 kB 1.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 4.2 MB 8.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 49 kB 4.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 150 kB 61.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 113 kB 62.2 MB/s \n",
            "\u001b[?25h  Building wheel for kaggle-cli (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for lxml (setup.py) ... \u001b[?25lerror\n",
            "\u001b[31m  ERROR: Failed building wheel for lxml\u001b[0m\n",
            "\u001b[?25h  Building wheel for PrettyTable (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for pyperclip (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "    Running setup.py install for lxml ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[31mERROR: Command errored out with exit status 1: /usr/bin/python3 -u -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-install-7auyvrdj/lxml_acf0de770b7746fba9fd7b18a068a464/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-install-7auyvrdj/lxml_acf0de770b7746fba9fd7b18a068a464/setup.py'\"'\"';f = getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__) if os.path.exists(__file__) else io.StringIO('\"'\"'from setuptools import setup; setup()'\"'\"');code = f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' install --record /tmp/pip-record-8ghasjq9/install-record.txt --single-version-externally-managed --compile --install-headers /usr/local/include/python3.7/lxml Check the logs for full command output.\u001b[0m\n",
            "{\"username\":\"romankosmodemyanskiy\",\"key\":\"bf69d9972f7afdeff6397ce9b56c7814\"}Downloading train.csv.zip to sample_data\n",
            " 91% 290M/318M [00:12<00:01, 22.5MB/s]\n",
            "100% 318M/318M [00:12<00:00, 27.1MB/s]\n"
          ]
        }
      ],
      "source": [
        "!pip install -q kaggle\n",
        "!pip install -q kaggle-cli\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp drive/MyDrive/kaggle.json ~/.kaggle/\n",
        "!cat ~/.kaggle/kaggle.json\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "!kaggle competitions download avito-demand-prediction -f train.csv -p sample_data/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "01JJXEvBuEAA"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fp9Nm835m7NM"
      },
      "source": [
        "1. Создать Dataset для загрузки данных (используем только числовые данные)\n",
        "2. Обернуть его в Dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Tp8wD4syvuts"
      },
      "outputs": [],
      "source": [
        "class AvitoDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, filepath, train=True):\n",
        "        df = pd.read_csv(filepath)\n",
        "        df['activation_date'] = pd.to_datetime(df['activation_date'])\n",
        "        df['month'] = df['activation_date'].dt.month\n",
        "        df['day'] = df['activation_date'].dt.day\n",
        "        df['weekday'] = df['activation_date'].dt.weekday\n",
        "\n",
        "        y = df['deal_probability']\n",
        "        X = df.drop(columns=['deal_probability'], axis=1).select_dtypes(exclude=['object', 'datetime64[ns]'])\n",
        "\n",
        "        X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=13, test_size = 0.25)\n",
        "\n",
        "        X_train = X_train.fillna(0)\n",
        "        X_test = X_test.fillna(0)\n",
        "\n",
        "        if train:\n",
        "          self.data = X_train\n",
        "          self.labels = np.array(y_train)\n",
        "        else:\n",
        "          self.data = X_test\n",
        "          self.labels = np.array(y_test)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return self.data.iloc[index, :].values, self.labels[index]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "eYvNGtHfLJ3Y"
      },
      "outputs": [],
      "source": [
        "batch_size = 1024\n",
        "\n",
        "train_dataset = AvitoDataset('sample_data/train.csv.zip')\n",
        "train_data_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, \n",
        "                                          shuffle=True, \n",
        "                                          #num_workers=2, \n",
        "                                          drop_last=True)\n",
        "\n",
        "test_dataset = AvitoDataset('sample_data/train.csv.zip', False)\n",
        "test_data_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, \n",
        "                                          shuffle=True, \n",
        "                                          #num_workers=2, \n",
        "                                          drop_last=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZxlhJQmmm_dE"
      },
      "source": [
        "3. Написать архитектуру сети, которая предсказывает число показов на основании числовых данных (вы всегда можете нагенерить дополнительных факторов). Сеть должна включать BatchNorm слои и Dropout (или НЕ включать, но нужно обосновать)\n",
        "4. Учить будем на функцию потерь с кагла (log RMSE) - нужно её реализовать\n",
        "5. Сравните сходимость Adam, RMSProp и SGD, сделайте вывод по качеству работы модели"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "irg1Jq8sS3QQ"
      },
      "outputs": [],
      "source": [
        "class Perceptron(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim, activation=\"relu\"):\n",
        "        super(Perceptron, self).__init__()\n",
        "        self.fc = nn.Linear(input_dim, output_dim)\n",
        "        self.activation = activation\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.fc(x)\n",
        "        if self.activation==\"relu\":\n",
        "            return F.relu(x)\n",
        "        if self.activation==\"sigmoid\":\n",
        "            return torch.sigmoid(x)\n",
        "        raise RuntimeError\n",
        "        \n",
        "\n",
        "class FeedForward(nn.Module):\n",
        "    # Пробовал добавить дополнительный слой с последующей нормализацией и дропаутом, но улучшения результата не удалось добиться\n",
        "    # Поэтому вернулся к архитектуре, представленной на уроке\n",
        "    def __init__(self, input_dim, hidden_dim):\n",
        "        super(FeedForward, self).__init__()\n",
        "        self.bn1 = nn.BatchNorm1d(input_dim)\n",
        "        self.fc1 = Perceptron(input_dim, hidden_dim)\n",
        "        self.bn2 = nn.BatchNorm1d(hidden_dim)\n",
        "        self.dp1 = nn.Dropout(0.2)\n",
        "        self.fc2 = Perceptron(hidden_dim, 1, activation='sigmoid')\n",
        "        self.double()\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.bn1(x)\n",
        "        x = self.fc1(x)\n",
        "        x = self.bn2(x)\n",
        "        x = self.dp1(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "# В соревновании на каггле использовалалсь метрика RMSE, поэтому реализовывал ее\n",
        "class RMSELoss(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(RMSELoss,self).__init__()\n",
        "\n",
        "    def forward(self,x,y):\n",
        "        criterion = nn.MSELoss()\n",
        "        eps = 1e-6\n",
        "        loss = torch.sqrt(criterion(x, y) + eps)\n",
        "        return loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "i7UE3-0yQcZY"
      },
      "outputs": [],
      "source": [
        "def train(dataloader, model, loss_fn, optimizer):\n",
        "    size = len(dataloader.dataset)\n",
        "    model.train()\n",
        "    for i, data in enumerate(dataloader):\n",
        "        inputs, labels = data[0], data[1]\n",
        "\n",
        "        # обнуляем градиент\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = model(inputs)\n",
        "        loss = loss_fn(outputs, labels.reshape(1024,-1))\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if i % 300 == 0:\n",
        "            loss, current = loss.item(), i * len(inputs)\n",
        "            print(f\"loss: {loss:>7f}  [{current:>8d}/{size:>8d}]\")\n",
        "\n",
        "\n",
        "\n",
        "def test(dataloader, model, loss_fn):\n",
        "    size = len(dataloader.dataset)\n",
        "    num_batches = len(dataloader)\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in dataloader:\n",
        "            outputs = model(inputs)\n",
        "            test_loss += loss_fn(outputs, labels.reshape(1024,-1)).item()\n",
        "    test_loss /= num_batches\n",
        "    print(f\"Test Error: \\n Avg loss: {test_loss:>8f} \\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "pxS7r2RBTKa0"
      },
      "outputs": [],
      "source": [
        "net = FeedForward(6, 30)\n",
        "\n",
        "optimizer = torch.optim.SGD(net.parameters(), lr=1e-3)\n",
        "criterion = RMSELoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iHawwrB7SkYg",
        "outputId": "022cb980-12d2-4dea-f206-67f7a7ddc940"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "-------------------------------\n",
            "loss: 0.481468  [       0/ 1127568]\n",
            "loss: 0.463155  [  307200/ 1127568]\n",
            "loss: 0.442622  [  614400/ 1127568]\n",
            "loss: 0.427547  [  921600/ 1127568]\n",
            "Test Error: \n",
            " Avg loss: 0.417899 \n",
            "\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "loss: 0.416945  [       0/ 1127568]\n",
            "loss: 0.406108  [  307200/ 1127568]\n",
            "loss: 0.397721  [  614400/ 1127568]\n",
            "loss: 0.388491  [  921600/ 1127568]\n",
            "Test Error: \n",
            " Avg loss: 0.371687 \n",
            "\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "loss: 0.370910  [       0/ 1127568]\n",
            "loss: 0.362188  [  307200/ 1127568]\n",
            "loss: 0.354867  [  614400/ 1127568]\n",
            "loss: 0.346678  [  921600/ 1127568]\n",
            "Test Error: \n",
            " Avg loss: 0.334741 \n",
            "\n",
            "Epoch 4\n",
            "-------------------------------\n",
            "loss: 0.333797  [       0/ 1127568]\n",
            "loss: 0.332681  [  307200/ 1127568]\n",
            "loss: 0.326494  [  614400/ 1127568]\n",
            "loss: 0.319778  [  921600/ 1127568]\n",
            "Test Error: \n",
            " Avg loss: 0.309056 \n",
            "\n",
            "Epoch 5\n",
            "-------------------------------\n",
            "loss: 0.312948  [       0/ 1127568]\n",
            "loss: 0.310885  [  307200/ 1127568]\n",
            "loss: 0.295701  [  614400/ 1127568]\n",
            "loss: 0.295022  [  921600/ 1127568]\n",
            "Test Error: \n",
            " Avg loss: 0.291048 \n",
            "\n",
            "Done!\n"
          ]
        }
      ],
      "source": [
        "epochs = 5\n",
        "for t in range(epochs):\n",
        "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "    train(train_data_loader, net, criterion, optimizer)\n",
        "    test(test_data_loader, net, criterion)\n",
        "print(\"Done!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Попробуем построить модели с другими оптимизаторами:"
      ],
      "metadata": {
        "id": "z8Mxr8vYj_Ck"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "aFFGGz7FVA_4"
      },
      "outputs": [],
      "source": [
        "net = FeedForward(6, 30)\n",
        "\n",
        "optimizer = torch.optim.Adam(net.parameters())\n",
        "criterion = RMSELoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iB4ZsIoSFiQI",
        "outputId": "23d5d733-1361-4570-dc52-188ca7c55c9a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "-------------------------------\n",
            "loss: 0.464453  [       0/ 1127568]\n",
            "loss: 0.257404  [  307200/ 1127568]\n",
            "loss: 0.254053  [  614400/ 1127568]\n",
            "loss: 0.246998  [  921600/ 1127568]\n",
            "Test Error: \n",
            " Avg loss: 0.253009 \n",
            "\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "loss: 0.251381  [       0/ 1127568]\n",
            "loss: 0.244445  [  307200/ 1127568]\n",
            "loss: 0.247974  [  614400/ 1127568]\n",
            "loss: 0.240892  [  921600/ 1127568]\n",
            "Test Error: \n",
            " Avg loss: 0.251903 \n",
            "\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "loss: 0.250829  [       0/ 1127568]\n",
            "loss: 0.249453  [  307200/ 1127568]\n",
            "loss: 0.255675  [  614400/ 1127568]\n",
            "loss: 0.258463  [  921600/ 1127568]\n",
            "Test Error: \n",
            " Avg loss: 0.252016 \n",
            "\n",
            "Epoch 4\n",
            "-------------------------------\n",
            "loss: 0.245201  [       0/ 1127568]\n",
            "loss: 0.249977  [  307200/ 1127568]\n",
            "loss: 0.251528  [  614400/ 1127568]\n",
            "loss: 0.244056  [  921600/ 1127568]\n",
            "Test Error: \n",
            " Avg loss: 0.251075 \n",
            "\n",
            "Epoch 5\n",
            "-------------------------------\n",
            "loss: 0.251464  [       0/ 1127568]\n",
            "loss: 0.246134  [  307200/ 1127568]\n",
            "loss: 0.259794  [  614400/ 1127568]\n",
            "loss: 0.257970  [  921600/ 1127568]\n",
            "Test Error: \n",
            " Avg loss: 0.250936 \n",
            "\n",
            "Done!\n"
          ]
        }
      ],
      "source": [
        "epochs = 5\n",
        "for t in range(epochs):\n",
        "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "    train(train_data_loader, net, criterion, optimizer)\n",
        "    test(test_data_loader, net, criterion)\n",
        "print(\"Done!\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "net = FeedForward(6, 30)\n",
        "\n",
        "optimizer = torch.optim.RMSprop(net.parameters(), lr=1e-3)\n",
        "criterion = RMSELoss()\n",
        "\n",
        "\n",
        "epochs = 5\n",
        "for t in range(epochs):\n",
        "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "    train(train_data_loader, net, criterion, optimizer)\n",
        "    test(test_data_loader, net, criterion)\n",
        "print(\"Done!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P78-7fZ6plzg",
        "outputId": "3ccb36da-5141-4d89-8faf-cd580d7206df"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "-------------------------------\n",
            "loss: 0.446455  [       0/ 1127568]\n",
            "loss: 0.267454  [  307200/ 1127568]\n",
            "loss: 0.249551  [  614400/ 1127568]\n",
            "loss: 0.236385  [  921600/ 1127568]\n",
            "Test Error: \n",
            " Avg loss: 0.251909 \n",
            "\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "loss: 0.251708  [       0/ 1127568]\n",
            "loss: 0.272383  [  307200/ 1127568]\n",
            "loss: 0.264237  [  614400/ 1127568]\n",
            "loss: 0.251765  [  921600/ 1127568]\n",
            "Test Error: \n",
            " Avg loss: 0.252839 \n",
            "\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "loss: 0.244552  [       0/ 1127568]\n",
            "loss: 0.243975  [  307200/ 1127568]\n",
            "loss: 0.244089  [  614400/ 1127568]\n",
            "loss: 0.256386  [  921600/ 1127568]\n",
            "Test Error: \n",
            " Avg loss: 0.251878 \n",
            "\n",
            "Epoch 4\n",
            "-------------------------------\n",
            "loss: 0.247568  [       0/ 1127568]\n",
            "loss: 0.248801  [  307200/ 1127568]\n",
            "loss: 0.252165  [  614400/ 1127568]\n",
            "loss: 0.247766  [  921600/ 1127568]\n",
            "Test Error: \n",
            " Avg loss: 0.252917 \n",
            "\n",
            "Epoch 5\n",
            "-------------------------------\n",
            "loss: 0.245207  [       0/ 1127568]\n",
            "loss: 0.249938  [  307200/ 1127568]\n",
            "loss: 0.246531  [  614400/ 1127568]\n",
            "loss: 0.256342  [  921600/ 1127568]\n",
            "Test Error: \n",
            " Avg loss: 0.251145 \n",
            "\n",
            "Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dxIGYaS4nG08"
      },
      "source": [
        "RMSprop и Adam сходятся быстрее, чем SGD. Результаты также довольно близки. Однако в сравнении с лидерами рейтинга соревнования на каггле видно, что качество модели довольно низкое. Это неудивительно с учетом небольшого количества признаков, на основе которых проводится обучение."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Аналогичное сравнение со средней ошибкой:"
      ],
      "metadata": {
        "id": "n0_khZu8LhuI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "#SGD\n",
        "net = FeedForward(6, 30)\n",
        "\n",
        "optimizer = torch.optim.SGD(net.parameters(), lr=1e-3)\n",
        "criterion = RMSELoss()\n",
        "\n",
        "\n",
        "for epoch in tqdm(range(10)):  \n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(train_data_loader, 0):\n",
        "        inputs, labels = data[0], data[1]\n",
        "\n",
        "        # обнуляем градиент\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, labels.reshape(1024, -1))\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # выводим статистику о процессе обучения\n",
        "        running_loss += loss.item()\n",
        "        if i % 300 == 299:    # печатаем каждые 300 mini-batches\n",
        "            print('[%d, %5d] loss: %.3f' %\n",
        "                  (epoch + 1, i + 1, running_loss / 300))\n",
        "            running_loss = 0.0\n",
        "\n",
        "print('Training is finished!')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sqsyqw337uyI",
        "outputId": "1756c3ac-7bce-4a2c-e0b9-78cc1690617f"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/10 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1,   300] loss: 0.480\n",
            "[1,   600] loss: 0.460\n",
            "[1,   900] loss: 0.441\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 10%|█         | 1/10 [02:43<24:30, 163.36s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2,   300] loss: 0.412\n",
            "[2,   600] loss: 0.398\n",
            "[2,   900] loss: 0.386\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|██        | 2/10 [05:27<21:52, 164.09s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[3,   300] loss: 0.367\n",
            "[3,   600] loss: 0.358\n",
            "[3,   900] loss: 0.349\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 30%|███       | 3/10 [08:09<19:00, 162.93s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[4,   300] loss: 0.336\n",
            "[4,   600] loss: 0.330\n",
            "[4,   900] loss: 0.323\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|████      | 4/10 [10:51<16:15, 162.51s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[5,   300] loss: 0.314\n",
            "[5,   600] loss: 0.309\n",
            "[5,   900] loss: 0.305\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|█████     | 5/10 [13:31<13:28, 161.78s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[6,   300] loss: 0.299\n",
            "[6,   600] loss: 0.295\n",
            "[6,   900] loss: 0.292\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|██████    | 6/10 [16:16<10:51, 162.78s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[7,   300] loss: 0.288\n",
            "[7,   600] loss: 0.285\n",
            "[7,   900] loss: 0.283\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 70%|███████   | 7/10 [19:00<08:09, 163.30s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[8,   300] loss: 0.280\n",
            "[8,   600] loss: 0.278\n",
            "[8,   900] loss: 0.277\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|████████  | 8/10 [21:45<05:27, 163.56s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[9,   300] loss: 0.274\n",
            "[9,   600] loss: 0.274\n",
            "[9,   900] loss: 0.272\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 90%|█████████ | 9/10 [24:28<02:43, 163.42s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[10,   300] loss: 0.271\n",
            "[10,   600] loss: 0.270\n",
            "[10,   900] loss: 0.269\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [27:12<00:00, 163.24s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training is finished!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Adam\n",
        "net = FeedForward(6, 30)\n",
        "\n",
        "optimizer = torch.optim.Adam(net.parameters())\n",
        "criterion = RMSELoss()\n",
        "\n",
        "\n",
        "for epoch in tqdm(range(10)):  \n",
        "    running_loss = 0.0\n",
        "    print()\n",
        "    for i, data in enumerate(train_data_loader, 0):\n",
        "        inputs, labels = data[0], data[1]\n",
        "\n",
        "        # обнуляем градиент\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, labels.reshape(1024, -1))\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # выводим статистику о процессе обучения\n",
        "        running_loss += loss.item()\n",
        "        if i % 300 == 299:    # печатаем каждые 300 mini-batches\n",
        "            print('[%d, %5d] loss: %.3f' %\n",
        "                  (epoch + 1, i + 1, running_loss / 300))\n",
        "            running_loss = 0.0\n",
        "\n",
        "print('Training is finished!')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "71gP-s6w70hU",
        "outputId": "fcd5256b-3f99-42be-ab17-848f7437a345"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/10 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[1,   300] loss: 0.322\n",
            "[1,   600] loss: 0.257\n",
            "[1,   900] loss: 0.255\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 10%|█         | 1/10 [02:43<24:31, 163.48s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[2,   300] loss: 0.254\n",
            "[2,   600] loss: 0.253\n",
            "[2,   900] loss: 0.252\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|██        | 2/10 [05:26<21:45, 163.20s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[3,   300] loss: 0.252\n",
            "[3,   600] loss: 0.252\n",
            "[3,   900] loss: 0.252\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 30%|███       | 3/10 [08:09<19:03, 163.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[4,   300] loss: 0.251\n",
            "[4,   600] loss: 0.252\n",
            "[4,   900] loss: 0.251\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|████      | 4/10 [10:56<16:26, 164.47s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[5,   300] loss: 0.251\n",
            "[5,   600] loss: 0.251\n",
            "[5,   900] loss: 0.251\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|█████     | 5/10 [13:39<13:40, 164.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[6,   300] loss: 0.251\n",
            "[6,   600] loss: 0.251\n",
            "[6,   900] loss: 0.251\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|██████    | 6/10 [16:26<11:00, 165.17s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[7,   300] loss: 0.250\n",
            "[7,   600] loss: 0.251\n",
            "[7,   900] loss: 0.251\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 70%|███████   | 7/10 [19:09<08:13, 164.43s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[8,   300] loss: 0.250\n",
            "[8,   600] loss: 0.251\n",
            "[8,   900] loss: 0.251\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|████████  | 8/10 [21:54<05:28, 164.41s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[9,   300] loss: 0.251\n",
            "[9,   600] loss: 0.250\n",
            "[9,   900] loss: 0.250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 90%|█████████ | 9/10 [24:40<02:44, 164.85s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[10,   300] loss: 0.251\n",
            "[10,   600] loss: 0.250\n",
            "[10,   900] loss: 0.250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [27:28<00:00, 164.89s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training is finished!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "В этом случае разница со скоростью сходимости между разными оптимизаторами еще более заметна."
      ],
      "metadata": {
        "id": "Cl5wxHpeeUes"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class FeedForward2(nn.Module):\n",
        "    # Другая архитектура сети\n",
        "    def __init__(self, input_dim, hidden_dim):\n",
        "        super(FeedForward2, self).__init__()\n",
        "        self.bn1 = nn.BatchNorm1d(input_dim)\n",
        "        self.fc1 = Perceptron(input_dim, 2*hidden_dim)\n",
        "        self.dp1 = nn.Dropout(0.3)\n",
        "        self.fc2 = Perceptron(2*hidden_dim, hidden_dim)\n",
        "        self.bn2 = nn.BatchNorm1d(hidden_dim)\n",
        "        self.fc3 = Perceptron(hidden_dim, 1, activation='sigmoid')\n",
        "        self.double()\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.bn1(x)\n",
        "        x = self.fc1(x)\n",
        "        x = self.dp1(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.bn2(x)\n",
        "        x = self.fc3(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "AEbI76cGC86s"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Adam\n",
        "net = FeedForward2(6, 30)\n",
        "\n",
        "optimizer = torch.optim.Adam(net.parameters())\n",
        "criterion = RMSELoss()\n",
        "\n",
        "\n",
        "for epoch in tqdm(range(10)):  \n",
        "    running_loss = 0.0\n",
        "    print()\n",
        "    for i, data in enumerate(train_data_loader, 0):\n",
        "        inputs, labels = data[0], data[1]\n",
        "\n",
        "        # обнуляем градиент\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, labels.reshape(1024, -1))\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # выводим статистику о процессе обучения\n",
        "        running_loss += loss.item()\n",
        "        if i % 300 == 299:    # печатаем каждые 300 mini-batches\n",
        "            print('[%d, %5d] loss: %.3f' %\n",
        "                  (epoch + 1, i + 1, running_loss / 300))\n",
        "            running_loss = 0.0\n",
        "\n",
        "print('\\nTraining is finished!')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uG-jJ8QfgKYA",
        "outputId": "b15705f8-2155-44b6-97bb-94ab69a1cb10"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/10 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[1,   300] loss: 0.314\n",
            "[1,   600] loss: 0.252\n",
            "[1,   900] loss: 0.252\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 10%|█         | 1/10 [02:55<26:20, 175.66s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[2,   300] loss: 0.251\n",
            "[2,   600] loss: 0.251\n",
            "[2,   900] loss: 0.250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|██        | 2/10 [05:43<22:47, 170.94s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[3,   300] loss: 0.250\n",
            "[3,   600] loss: 0.249\n",
            "[3,   900] loss: 0.249\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 30%|███       | 3/10 [08:30<19:44, 169.15s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[4,   300] loss: 0.249\n",
            "[4,   600] loss: 0.248\n",
            "[4,   900] loss: 0.250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|████      | 4/10 [11:18<16:51, 168.60s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[5,   300] loss: 0.249\n",
            "[5,   600] loss: 0.249\n",
            "[5,   900] loss: 0.248\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|█████     | 5/10 [14:07<14:05, 169.03s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[6,   300] loss: 0.249\n",
            "[6,   600] loss: 0.248\n",
            "[6,   900] loss: 0.249\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|██████    | 6/10 [16:54<11:12, 168.23s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[7,   300] loss: 0.249\n",
            "[7,   600] loss: 0.248\n",
            "[7,   900] loss: 0.248\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 70%|███████   | 7/10 [19:48<08:30, 170.21s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[8,   300] loss: 0.248\n",
            "[8,   600] loss: 0.249\n",
            "[8,   900] loss: 0.249\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|████████  | 8/10 [22:34<05:37, 168.73s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[9,   300] loss: 0.248\n",
            "[9,   600] loss: 0.248\n",
            "[9,   900] loss: 0.249\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 90%|█████████ | 9/10 [25:18<02:47, 167.42s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[10,   300] loss: 0.249\n",
            "[10,   600] loss: 0.247\n",
            "[10,   900] loss: 0.248\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [28:07<00:00, 168.72s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training is finished!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Заметной разницы в результатах не наблюдается."
      ],
      "metadata": {
        "id": "cGA_9ziPwFr8"
      }
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "HW3.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}